{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fashion_mnist_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5crwQcp-u7l5",
        "colab_type": "text"
      },
      "source": [
        "# Set up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pH7-urL5mLEV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L83ZlFafmScV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow\n",
        "print(tensorflow.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8FRIkNDj3SO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnK-ytnhlcRx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorboard.plugins.hparams import api as hp\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1s0Xrw1vJLe",
        "colab_type": "text"
      },
      "source": [
        "# Import Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmdiODx3h2fX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(train_data, train_labels), (test_data, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "# Names of the integer classes, i.e., 0 -> T-short/top, 1 -> Trouser, etc.\n",
        "CLASS_NAMES = np.array(['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot'])\n",
        "CLASS_NAMES\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApT-vjYqnwN5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = tf.cast(train_data, tf.float32)\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_data, train_labels)).shuffle(train_data.shape[0])\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_data, test_labels)).shuffle(test_data.shape[0])\n",
        "\n",
        "print(train_data.shape)\n",
        "print(train_labels.shape)\n",
        "print(test_data.shape)\n",
        "print(test_labels.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2dWZyZ_kSKE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_batch(ds):\n",
        "  plt.figure(figsize=(10,10))\n",
        "  i = 0\n",
        "  for data, label in ds.take(25):\n",
        "      ax = plt.subplot(5,5,i+1)\n",
        "      plt.imshow(data)\n",
        "      plt.title(CLASS_NAMES[label])\n",
        "      plt.axis('off')\n",
        "      i = i+1\n",
        "\n",
        "show_batch(test_dataset)     "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QoO7PhBzvN0B",
        "colab_type": "text"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_ecZT5ev0V4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Classifier(tf.keras.Model):\n",
        "  def __init__(self, num_units=64, conv_filter=32, dropout=0.1, num_classes=10):\n",
        "    super(Classifier, self).__init__(name='classifier')\n",
        "    self.num_classes = num_classes\n",
        "    self.conv = keras.layers.Conv2D(conv_filter, (3, 3), activation='relu', padding='valid')\n",
        "    self.max_pool = keras.layers.MaxPooling2D(pool_size=(2, 2))\n",
        "    self.flatten = keras.layers.Flatten()\n",
        "    self.dense_1 = keras.layers.Dense(num_units, activation='relu')\n",
        "    self.dropout = keras.layers.Dropout(dropout)\n",
        "    self.dense_2 = keras.layers.Dense(num_classes, activation='softmax')\n",
        "  def call(self, inputs):\n",
        "    # Define your forward pass here,\n",
        "    # using layers you previously defined (in `__init__`).\n",
        "    inputs = tf.expand_dims(inputs, 3)\n",
        "    x = self.conv(inputs)\n",
        "    x = self.max_pool(x)\n",
        "    x = self.flatten(x)\n",
        "    x = self.dense_1(x)\n",
        "    x = self.dropout(x)\n",
        "    return self.dense_2(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIEYzVXexrNG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(num_units=64, conv_filter=32, dropout=0.1, batch_size=32, epochs=5, num_classes=10):\n",
        "  train_ds = train_dataset.batch(batch_size)\n",
        "  test_ds = test_dataset.batch(batch_size)\n",
        "  classifier = Classifier(num_units=num_units, \n",
        "                          conv_filter=conv_filter,\n",
        "                          dropout=dropout, \n",
        "                          num_classes=num_classes)\n",
        "  classifier.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])\n",
        "  classifier.fit(train_ds, callbacks=[tensorboard_callback], epochs=epochs)\n",
        "  _, accuracy = classifier.evaluate(test_ds)\n",
        "  return accuracy\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsBO2eIb2Hh5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "train(num_units=128)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiZSvWJx2Otv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorboard --logdir logs/scalars"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50JmGCkF2QQ3",
        "colab_type": "text"
      },
      "source": [
        "# Hyper Parameters Tunning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z72_DL64yTS_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf ./logs/\n",
        "\n",
        "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "\n",
        "HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([32, 64]))\n",
        "HP_CONV_FILTER = hp.HParam('conv_filter', hp.Discrete([32]))\n",
        "HP_DROPOUT = hp.HParam('dropout', hp.Discrete([0.1]))\n",
        "HP_EPOCHS = hp.HParam('ephchs', hp.Discrete([5, 10]))\n",
        "HP_BATCH_SIZE = hp.HParam('batch_size', hp.Discrete([32, 64]))\n",
        "METRIC_ACCURACY = 'accuracy'\n",
        "\n",
        "with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
        "  hp.hparams_config(\n",
        "    hparams=[HP_NUM_UNITS, HP_CONV_FILTER, HP_DROPOUT, HP_EPOCHS, HP_BATCH_SIZE],\n",
        "    metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')],\n",
        "  )\n",
        "\n",
        "def run(run_dir, hparams):\n",
        "  with tf.summary.create_file_writer(run_dir).as_default():\n",
        "    hp.hparams(hparams)\n",
        "    accuracy = train(num_units=hparams[HP_NUM_UNITS],\n",
        "                     conv_filter=hparams[HP_CONV_FILTER],\n",
        "                     dropout=hparams[HP_DROPOUT],\n",
        "                     batch_size=hparams[HP_BATCH_SIZE],\n",
        "                     epochs=hparams[HP_EPOCHS])\n",
        "    tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)\n",
        "\n",
        "session_num = 0\n",
        "for num_units in HP_NUM_UNITS.domain.values:\n",
        "  for conv_filter in HP_CONV_FILTER.domain.values:\n",
        "    for dropout in HP_DROPOUT.domain.values:\n",
        "      for epochs in HP_EPOCHS.domain.values:\n",
        "        for batch_size in HP_BATCH_SIZE.domain.values:\n",
        "          hparams = {\n",
        "              HP_NUM_UNITS: num_units,\n",
        "              HP_CONV_FILTER: conv_filter,\n",
        "              HP_DROPOUT: dropout,\n",
        "              HP_EPOCHS: epochs,\n",
        "              HP_BATCH_SIZE: batch_size,\n",
        "              }\n",
        "          run_name = \"run-%d\" % session_num\n",
        "          print('--- Starting trial: %s' % run_name)\n",
        "          print({h.name: hparams[h] for h in hparams})\n",
        "          run('logs/hparam_tuning/' + run_name, hparams)\n",
        "          session_num += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6PUzO96t8OI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorboard --logdir logs/hparam_tuning"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suW5keu6vRZE",
        "colab_type": "text"
      },
      "source": [
        "# Predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yX4qX2CXlgJ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random \n",
        "  \n",
        "idx = random.randint(0, test_data.shape[0]) \n",
        "validation_data = test_data[idx:idx+1]\n",
        "print(validation_data.shape)\n",
        "predictions = classifier.predict(validation_data)\n",
        "print(predictions.shape)\n",
        "pred = CLASS_NAMES[np.argmax(predictions)]\n",
        "want = CLASS_NAMES[test_labels[idx]]\n",
        "print(\"pred: \", pred)\n",
        "print(\"want: \", want)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wc6p876RNy5Y",
        "colab_type": "text"
      },
      "source": [
        "#Reference\n",
        "\n",
        "*   https://www.tensorflow.org/guide/keras/train_and_evaluate#training_evaluation_from_tfdata_datasets\n",
        "*   https://gist.github.com/datlife/abfe263803691a8864b7a2d4f87c4ab8\n",
        "*   https://lambdalabs.com/blog/tensorflow-2-0-tutorial-01-image-classification-basics/\n",
        "*   https://keras.io/layers/convolutional/\n",
        "*   https://github.com/keras-team/keras/issues/3385\n",
        "\n"
      ]
    }
  ]
}